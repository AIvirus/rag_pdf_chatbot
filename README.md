
# ğŸ“š RAG PDF Chatbot (LangChain + Gemini + Hugging Face)

A simple, powerful chatbot app built using LangChain, Streamlit, Google Gemini Embeddings, and HuggingFace Hub models like `flan-t5-large`. This app lets you **upload multiple PDF files**, process them into chunks, generate embeddings, and ask questions in natural languageâ€”getting **context-aware answers** from your documents in real-time.

---

## ğŸ§  What is RAG?

**RAG** (Retrieval-Augmented Generation) is an architecture that combines:
- ğŸ” **Retrieval**: Searching relevant chunks from a document database (vector store)
- ğŸ¤– **Generation**: Answering your question using a language model (LLM), grounded in the retrieved context

---

## âœ¨ Features

- Upload multiple PDFs and query them
- Uses Google Gemini API for custom embeddings
- FAISS as an in-memory vector store
- Conversational memory for chat history
- Works with Hugging Face LLMs (like `flan-t5-large`)
- Clean web interface via Streamlit

---

## ğŸ“ Project Structure

```
rag_pdf_chatbot/
â”‚
â”œâ”€â”€ app.py                     # Streamlit app
â”œâ”€â”€ templates.py               # HTML/CSS templates for chatbot messages
â”œâ”€â”€ .env                       # Contains GEMINI_API_KEY, OPEN_AI_API_KEY and HF_API_KEY
â”œâ”€â”€ requirements.txt           # All dependencies
â”œâ”€â”€ test.py                    # to test api key properly loading or not
â””â”€â”€ README.md                  # You're reading it!
```

---

## ğŸ› ï¸ Setup Instructions

### âœ… Prerequisites

- Python 3.10
- [HuggingFace API Key](https://huggingface.co/settings/tokens)
- [Google AI Studio Gemini API Key](https://makersuite.google.com/app)

### ğŸ”§ Create Environment (Optional via Conda)

```bash
# Open terminal or Anaconda Prompt
conda create -n rag310 python=3.10
conda activate rag310
```

### ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ”‘ Create `.env` File

```env
GEMINI_API_KEY=your_google_gemini_api_key
HUGGINGFACEHUB_API_TOKEN=your_huggingface_api_key
```

---

## ğŸš€ Run the App

```bash
streamlit run app.py
```

Then go to `http://localhost:8501` in your browser.

---

## ğŸ–¼ï¸ Screenshots

> Add screenshots of your UI here (upload images to GitHub or embed directly)

---

## ğŸ’¡ Example Models

- `google/flan-t5-large` via Hugging Face
- You can replace it with other HuggingFace-supported models

---

## ğŸ”Œ Technologies Used

- **Streamlit** â€“ Web UI
- **LangChain** â€“ Orchestration
- **FAISS** â€“ Vector DB
- **Gemini API** â€“ Embeddings
- **HuggingFace** â€“ Language model inference

---

## ğŸ“ƒ License

MIT License

---

## ğŸ™Œ Credits

Built with â¤ï¸ by Praveen Roy

---
